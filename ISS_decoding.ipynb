{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"RcRL-BRq3NFV"},"source":["# Lab: ISS decoding\n","\n","## Using starfish pixel spot decoder"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"P4BoQAgq3NFY"},"source":["Once the data is correctly loaded and processed, we are in the position of decoding the actual ISS spots. To this end, we will use again **starfish**, find the original tutorial [here](https://spacetx-starfish.readthedocs.io/en/mcai-api-additions/gallery/tutorials/pixelbased_decoding.html#sphx-glr-gallery-tutorials-pixelbased-decoding-py):\n","\n","> Pixel-based decoding is the approach of localizing and decoding<sup>1</sup> molecules (e.g. RNA transcripts or rolonies) that does not rely on algorithms to find spots by fitting Gaussian profiles or local intensity maxima. Instead of finding spots to be decoded, it decodes every pixel and then connects potential pixels with the same codeword<sup>2</sup> from the codebook<sup>3</sup>  into spots. The strength of this approach is it works on dense data and noisy data where spot finding algorithms have a hard time accurately detecting spots. The weakness is that it is prone to false positives by decoding noise that would normally be ignored by spot finding algorithms.\n","\n","[1]: Matching putative barcodes to codewords in a codebook to read out the corresponding target believed to be associated with that barcode.\n","\n","[2]: A codeword maps expected intensities across multiple image tiles within a field of view to the target that is encoded by the codeword.\n","\n","[3]: A codebook contains all the codewords needed by an experiment to decode an IntensityTable. It also contains a mapping of channels to the integer indices that are used by starfish to represent them internally."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-79YAWR_Elg7"},"outputs":[],"source":["# We install dependencies, including the latest version of starfish\n","# This step can take up to 10 minutes!\n","\n","!apt update\n","!apt install libvips tree\n","!pip install tissuumaps\n","!pip install git+https://github.com/spacetx/starfish@853f56c7c02b15397adb921db5e3bde02fdadb63"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1687436959280,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"YzZNW9oO9kIv"},"outputs":[],"source":["# We download some helper functions and quality control plugins\n","\n","from urllib import request\n","import os\n","os.makedirs(\"./iss_utils\", exist_ok=True)\n","request.urlretrieve( 'https://raw.githubusercontent.com/wahlby-lab/ISS_Decoding_colab/main/iss_utils/__init__.py' , './iss_utils/__init__.py' )\n","request.urlretrieve( 'https://raw.githubusercontent.com/wahlby-lab/ISS_Decoding_colab/main/iss_utils/read_starfish.py' , './iss_utils/read_starfish.py' )\n","request.urlretrieve( 'https://raw.githubusercontent.com/wahlby-lab/ISS_Decoding_colab/main/iss_utils/starfish2tmap.py' , './iss_utils/starfish2tmap.py' )\n","\n","os.makedirs(os.path.join(os.path.expanduser(\"~\"), \".tissuumaps\", \"plugins\"), exist_ok = True)\n","for ext in [\".py\",\".js\",\".yml\"]:\n","    request.urlretrieve(\n","        \"https://raw.githubusercontent.com/TissUUmaps/TissUUmaps/11f635fb1b9c5fa69e4d15735c1a9f833ab74af3/plugins_repo/Spot_Inspector\" + ext,\n","        os.path.join(os.path.expanduser(\"~\"), \".tissuumaps\", \"plugins\", 'Spot_Inspector' + ext)\n","    )\n","    request.urlretrieve(\n","        \"https://raw.githubusercontent.com/TissUUmaps/TissUUmaps/master/plugins_repo/latest/Points2Regions\" + ext,\n","        os.path.join(os.path.expanduser(\"~\"), \".tissuumaps\", \"plugins\", 'Points2Regions' + ext)\n","    )"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BpeZQcYX3NFa"},"source":["We take a tile from the raw data:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12931,"status":"ok","timestamp":1687436079574,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"zarPemY93NFc","outputId":"a414754e-6cca-4fbf-f1d0-475c6b1c2269"},"outputs":[],"source":["from urllib import request\n","import tarfile\n","from tqdm import tqdm\n","import os\n","\n","os.makedirs(\"./data/\", exist_ok=True)\n","base_path = \"https://export.uppmax.uu.se/snic2022-23-113/courses/spatial_omics_2022/in_situ_sequencing/\"\n","\n","# Download necessary tar.gz files\n","for tar_file in [\"SpaceTX_1_fov.tar.gz\"]:\n","    print (\"Downloading \" + base_path + tar_file)\n","    request.urlretrieve( base_path+tar_file , \"./data/\"+tar_file )\n","\n","# Unzip tar.gz files\n","for tar_file in [\"SpaceTX_1_fov.tar.gz\"]:\n","    print (\"Unzipping \" + \"./data/\" + tar_file)\n","    tar = tarfile.open(\"./data/\" + tar_file, \"r:gz\")\n","\n","    progress = tqdm(tar.getmembers())\n","    for member in progress:\n","        tar.extract(member, path=\"./data/\")\n","        # set the progress description of the progress bar\n","        progress.set_description(f\"Extracting {member.name}\")\n","    tar.close()\n","\n","!tree --filelimit=100 ./data/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5906,"status":"ok","timestamp":1687435937453,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"GPHIEzIW3NFe","outputId":"dcfe8f33-6aca-4e9f-bde5-80edd1ea9ff1"},"outputs":[],"source":["import tissuumaps.jupyter as tm\n","\n","import numpy as np\n","import os\n","from starfish import Experiment, display\n","from starfish.image import Filter\n","from starfish.spots import DetectPixels\n","from starfish.types import Features, Axes\n","\n","from starfish import IntensityTable\n","from iss_utils import starfish2tmap, tmap_to_colab"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":278,"status":"ok","timestamp":1687436097681,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"FOTXnTeB3NFf"},"outputs":[],"source":["input_path = './data/SpaceTX_1_fov'\n","sel_fov = 'fov_045'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1687436442204,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"onqNGSVU3NFg","scrolled":false},"outputs":[],"source":["import glob\n","\n","raw_images = sorted(glob.glob(input_path + \"/*.tiff\"))\n","viewer = tm.loaddata(images=raw_images, plugins=[\"Spot_Inspector\"], compositeMode=\"lighter\")\n","tmap_to_colab(viewer, iframe=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1196,"status":"ok","timestamp":1687436371986,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"ONiDX6AY3NFh"},"outputs":[],"source":["exp = Experiment.from_json(\n","    os.path.join(input_path, \"experiment.json\")\n",")\n","imgs_primary = exp[sel_fov].get_image('primary')\n","imgs_nuclei  = exp[sel_fov].get_image('nuclei')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1687436372918,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"-Jws3M8V3NFi","outputId":"de2783bc-b417-4b4a-b333-1be2d1155544"},"outputs":[],"source":["imgs_primary"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AYb0D-wP3NFi"},"source":["Following the tutorial, first we will apply high and low pass filters, designed to smooth the data before detecting the spots."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10360,"status":"ok","timestamp":1687436385177,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"CN22AiW_3NFj","outputId":"5bd6657a-c8ff-4dc0-a386-f045423ea95d","scrolled":true},"outputs":[],"source":["# filter and deconvolve data\n","ghp = Filter.GaussianHighPass(sigma=3)\n","glp = Filter.GaussianLowPass(sigma=1)\n","\n","ghp.run(imgs_primary, in_place=True)\n","glp.run(imgs_primary, in_place=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5KW32pHY3NFj"},"source":["We can compare some random tiles before and after filtering:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6582,"status":"ok","timestamp":1687436391755,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"mAHID5xn3NFj","outputId":"70bd3fe1-0d4b-4664-e23c-7c14661e814b"},"outputs":[],"source":["%matplotlib inline\n","starfish2tmap.compare_images(\n","    exp[sel_fov].get_image('primary'),\n","    imgs_primary,\n","    n=3\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Rw6VTfG13NFk"},"source":["We can already use some kind of decoding to detect the expressed genes. In this case, we will use a pixel spot decoder. This can yield suboptimal results in terms of detection, but we will still use if for simiplicity sake. There are other approaches for performing this such as [bardensr](https://github.com/jacksonloper/bardensr) or [ISTDECO](https://github.com/axanderssonuu/istdeco) that allow decoding with a better performance.\n","\n","There are some hyperparameters that need to be tuned, but the most important input to the function is the **codebook** that contain which combination of rounds and channels (barcode) is translated to a specific gene.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50089,"status":"ok","timestamp":1687436441841,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"sI0DevPA3NFk","outputId":"6ea18765-5d23-4aa7-b1dc-d46ce69f83e9"},"outputs":[],"source":["psd = DetectPixels.PixelSpotDecoder(\n","    codebook=exp.codebook,\n","    metric='euclidean',             # distance metric to use for computing distance between a pixel vector and a codeword\n","    norm_order=2,                   # the L_n norm is taken of each pixel vector and codeword before computing the distance. this is n\n","    distance_threshold=0.5176,      # minimum distance between a pixel vector and a codeword for it to be called as a gene\n","    magnitude_threshold=1.77e-5,    # discard any pixel vectors below this magnitude\n","    min_area=2,                     # do not call a 'spot' if it's area is below this threshold (measured in pixels)\n","    max_area=np.inf,                # do not call a 'spot' if it's area is above this threshold (measured in pixels)\n",")\n","initial_spot_intensities, prop_results = psd.run(imgs_primary, n_processes=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1687436441843,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"kvqSY_Jo3NFl","outputId":"c9e1317a-6ed7-4c8e-ea4d-cbb01804eeca"},"outputs":[],"source":["initial_spot_intensities"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2NMwjlue3NFl"},"source":["These approaches usually yield too many false positives, so it is a good dea to threshold based on random codes included for this purpose."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1687436441843,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"s-at5XJy3NFl"},"outputs":[],"source":["# filter spots that do not pass thresholds\n","spot_intensities = initial_spot_intensities.loc[initial_spot_intensities[Features.PASSES_THRESHOLDS]]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Zrnmsi_t3NFm"},"source":["This is how the decoded intensity table looks like:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1687436441844,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"Puqt9zJh3NFm","outputId":"6212d8af-bc63-4c63-fda2-ea38591d6001"},"outputs":[],"source":["spot_intensities"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QuMnbh4d3NFn"},"source":["Example of how to access the spot attributes:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1687436441845,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"-onsfrof3NFn","outputId":"812c2da0-50ef-4dbd-a929-f7626e98d932","scrolled":true},"outputs":[],"source":["print(f\"The area of the first spot is {prop_results.region_properties[0].area}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1hGtCV9C3NFn"},"source":["Let's save it before continuing with the quality control using TissUUmaps. Starfish has a method for this:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1687436501771,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"bqTs-NWW3NFo","scrolled":false},"outputs":[],"source":["os.makedirs(\"./results\", exist_ok=True)\n","spot_intensities.to_netcdf('./results/spot_intensities.netcdf')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RU18HmOr3NFo"},"source":["# ISS decoding quality control\n","\n","For this last step, we will use the TissUUmaps [Spot Inspector](https://tissuumaps.github.io/tutorials/#spot_inspector) plugin to visually assess the quality of the decoding. This plugin allows to explore raw in situ sequencing data by visualizing a grid of rounds and channels and drawing the trace of the codeword that the decoding algorithm decided to assign to a particular spot. Thus, in a visual and intuitive way, one may see if the decoding corresponds to what the raw data and potentially detect some error sources.\n","\n","To begin, we will load the spot intensities saved in the previous part of the lab."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1687436504279,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"Y8yWtF4n3NFo"},"outputs":[],"source":["spot_intensities = IntensityTable.open_netcdf('./results/spot_intensities.netcdf')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bIfUToY83NFp"},"source":["We developed a series of helper functions that will allow adapting the starfish files for opening in TissUUmaps. For more information, visit [the website](https://tissuumaps.github.io/tutorials/#starfish).\n","\n","First, we will create a CSV file from a starfish experiments compatible with the TissUUmaps Spot Insepector plugin."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4348,"status":"ok","timestamp":1687436511992,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"QcEIc81Y3NFp"},"outputs":[],"source":["os.makedirs('./results/decoded', exist_ok=True)\n","csv_name = starfish2tmap.qc_csv(\n","    experiment=exp,\n","    spot_intensities=spot_intensities,\n","    output_path='./results/decoded'\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6QJqQ_z73NFp"},"source":["Now, we can create the images from a starfish experiments to show for the Spot Inspector plugin."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10851,"status":"ok","timestamp":1687436522840,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"fzh7OdxM3NFq","outputId":"7e4ba7c5-23e4-40f6-a033-e00a74155d3d","scrolled":true},"outputs":[],"source":["image_names = starfish2tmap.qc_images(\n","    imgs_primary,\n","    imgs_nuclei,\n","    output_path='./results/decoded'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1687436522841,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"fWqfQ_2H3NFq","outputId":"f4b99533-a3eb-4d5e-b807-6bb6df07d7bf"},"outputs":[],"source":["!tree --filelimit=100 ./results/decoded/"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NzLIHZzV3NFq"},"source":["Finally, we can open TissUUmaps inside this notebook and play around with the plugin. Find some good and bad examples of decodings and try to think what went wrong with a particular spot."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1932,"status":"ok","timestamp":1687436973054,"user":{"displayName":"Christophe Avenel","userId":"05355984956705765793"},"user_tz":-120},"id":"J722mn3N3NFr","outputId":"b6e34bb0-69f8-42de-fbc5-c2d5e46f6f18","scrolled":false},"outputs":[],"source":["viewer = tm.loaddata(images=image_names,csvFiles= csv_name, plugins=[\"Spot_Inspector\",\"Points2Regions\"], keySelector=\"target_name\", port=5108)\n","tmap_to_colab(viewer, iframe=False)"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/NBISweden/workshop-spatial/blob/main/labs/02_ISS_decoding.ipynb","timestamp":1687434768405}]},"interpreter":{"hash":"56da8c84684b12a7b9d87f675c64cfab9b7838526e562de4bb2040c16d55d19a"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}
